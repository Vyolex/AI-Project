{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the required packages for our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import shutil\n",
    "from multiprocessing import Pool\n",
    "from evaluate_recommender import evaluate_recommender, generate_gt, map_id_to_name, parse_json\n",
    "from os import cpu_count\n",
    "from os.path import exists\n",
    "qual_eval_folder = './evaluation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the basic recommender using different distance metrics, tf-idf methods and disabling/enabling feedback weighting\n",
    "\n",
    "Distance metrics:\n",
    "- Euclidian distance: `sqrt(sum((x - y)^2))`\n",
    "- Cosine distance: $1-\\frac{x \\cdot y}{||x||_2||y||_2}$\n",
    "- Manhattan distance: `sum(|x - y|)`\n",
    "- Chebyshev distance: `max(|x - y|)`\n",
    "\n",
    "Tf-idf methods:\n",
    "- No tf-idf\n",
    "- default tf-idf: `tf(t, d) * [log [n/df(t)] + 1]`\n",
    "- smoothed tf-idf: `tf(t, d) * [log [(1+n)/(1+df(t))] + 1]`\n",
    "- sublinear tf-idf: `[1 + log(tf)] * [log [n/df(t)] + 1]`\n",
    "- smoothed sublinear tf-idf: `[1 + log(tf)] * [log [(1+n)/(1+df(t))] + 1]`\n",
    "\n",
    "Feedback weighting: will transform the feature vectors of items that were reviewed negatively to negative values (dislikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean None False: {'nDCG@k': 0.21217929154761547, 'recall@k': 0.025599964095272373}\n",
      "euclidean default False: {'nDCG@k': 0.2365792569708007, 'recall@k': 0.029979453947888618}\n",
      "euclidean smooth False: {'nDCG@k': 0.23675069163099288, 'recall@k': 0.029998350833202816}\n",
      "euclidean sublinear False: {'nDCG@k': 0.2365792569708007, 'recall@k': 0.029979453947888618}\n",
      "euclidean smooth_sublinear False: {'nDCG@k': 0.23675069163099288, 'recall@k': 0.029998350833202816}\n",
      "cosine None False: {'nDCG@k': 0.3416964808768842, 'recall@k': 0.04017819006225621}\n",
      "cosine default False: {'nDCG@k': 0.34589429604608735, 'recall@k': 0.040467501225920244}\n",
      "cosine smooth False: {'nDCG@k': 0.3460184542501682, 'recall@k': 0.04046616806914695}\n",
      "cosine sublinear False: {'nDCG@k': 0.34589429604608735, 'recall@k': 0.040467501225920244}\n",
      "cosine smooth_sublinear False: {'nDCG@k': 0.3460184542501682, 'recall@k': 0.04046616806914695}\n",
      "manhattan None False: {'nDCG@k': 0.21218879058172857, 'recall@k': 0.025591013030650714}\n",
      "manhattan default False: {'nDCG@k': 0.25778493789169693, 'recall@k': 0.032010298641733964}\n",
      "manhattan smooth False: {'nDCG@k': 0.25747977596996185, 'recall@k': 0.032016712385048406}\n",
      "manhattan sublinear False: {'nDCG@k': 0.25778493789169693, 'recall@k': 0.032010298641733964}\n",
      "manhattan smooth_sublinear False: {'nDCG@k': 0.25747977596996185, 'recall@k': 0.032016712385048406}\n",
      "cosine None True: {'nDCG@k': 0.3174122449675036, 'recall@k': 0.03708021143277947}\n",
      "cosine default True: {'nDCG@k': 0.32276615184897894, 'recall@k': 0.037560219582482485}\n",
      "cosine smooth True: {'nDCG@k': 0.32285281537075294, 'recall@k': 0.03755644341439623}\n",
      "cosine sublinear True: {'nDCG@k': 0.32276615184897894, 'recall@k': 0.037560219582482485}\n",
      "cosine smooth_sublinear True: {'nDCG@k': 0.32285281537075294, 'recall@k': 0.03755644341439623}\n"
     ]
    }
   ],
   "source": [
    "gt_file = './data/ground_truth.parquet'\n",
    "if not exists(gt_file):\n",
    "    generate_gt(gt_file)\n",
    "metrics = ['euclidean', 'cosine', 'manhattan']\n",
    "tfidf = [None, 'default', 'smooth', 'sublinear', 'smooth_sublinear']\n",
    "combinations = list(itertools.product(metrics, tfidf))\n",
    "with Pool(min(cpu_count(), len(combinations))) as pool:\n",
    "    results = [pool.apply_async(evaluate_recommender, args=(metric, tfidf, False, qual_eval_folder)) for metric, tfidf in combinations]\n",
    "    output = [p.get() for p in results]\n",
    "for result in output:\n",
    "    print(result[0], result[1], result[2], '\\b:', result[3])\n",
    "    \n",
    "with Pool(min(cpu_count(), len(tfidf))) as pool:\n",
    "    results = [pool.apply_async(evaluate_recommender, args=('cosine', tfidf_method, True, qual_eval_folder)) for tfidf_method in tfidf]\n",
    "    output = [p.get() for p in results]\n",
    "for result in output:\n",
    "    print(result[0], result[1], result[2], '\\b:', result[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(optional)  Create a .zip archive of the created qualitative evaluation files. This is done such that the qualitative evaluation results can be shared through GitHub.\n",
    "            \n",
    "    This step can be skipped if the file `evaluation.zip` is already present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive(f'{qual_eval_folder}/evaluation', 'zip', f'{qual_eval_folder}/source')\n",
    "shutil.rmtree(f'{qual_eval_folder}/source')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The qualitative evaluation results in `evaluation.zip` are provided in terms of item ids.\n",
    "In order to be able to interpret the results, the ids are mapped to application names through the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32135it [00:01, 21678.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 32135 rows.\n"
     ]
    }
   ],
   "source": [
    "shutil.unpack_archive(f'{qual_eval_folder}/evaluation.zip', qual_eval_folder)\n",
    "\n",
    "import glob\n",
    "games = parse_json(\"./data/steam_games.json\")\n",
    "games = games[['id', 'app_name']]\n",
    "mapping = dict(zip(games.id, games.app_name))\n",
    "for f in glob.glob(f'{qual_eval_folder}/*.csv'):\n",
    "    map_id_to_name(mapping, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64dc3e748883430fd73e07c7431dac127012ab88bcfa4187114a89d6e3756f23"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
