{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the required packages for our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import shutil\n",
    "from multiprocessing import Pool\n",
    "from evaluate_recommender import evaluate_recommender, generate_gt, map_id_to_name, parse_json\n",
    "from os import cpu_count\n",
    "from os.path import exists\n",
    "qual_eval_folder = './evaluation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the basic recommender using different distance metrics and tf-idf methods\n",
    "\n",
    "Distance metrics:\n",
    "- Euclidian distance: `sqrt(sum((x - y)^2))`\n",
    "- Cosine distance: $1-\\frac{x \\cdot y}{||x||_2||y||_2}$\n",
    "- Manhattan distance: `sum(|x - y|)`\n",
    "- Chebyshev distance: `max(|x - y|)`\n",
    "\n",
    "Tf-idf methods:\n",
    "- No tf-idf\n",
    "- default tf-idf: `tf(t, d) * [log [n/df(t)] + 1]`\n",
    "- smoothed tf-idf: `tf(t, d) * [log [(1+n)/(1+df(t))] + 1]`\n",
    "- sublinear tf-idf: `[1 + log(tf)] * [log [n/df(t)] + 1]`\n",
    "- smoothed sublinear tf-idf: `[1 + log(tf)] * [log [(1+n)/(1+df(t))] + 1]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-681ea28eb891>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "gt_file = './data/ground_truth.parquet'\n",
    "if not exists(gt_file):\n",
    "    generate_gt(gt_file)\n",
    "metrics = ['euclidean', 'cosine', 'manhattan']\n",
    "tfidf = [None, 'default', 'smooth', 'sublinear', 'smooth_sublinear']\n",
    "combinations = list(itertools.product(metrics, tfidf))\n",
    "with Pool(min(cpu_count(), len(combinations))) as pool:\n",
    "    results = [pool.apply_async(evaluate_recommender, args=(metric, tfidf, qual_eval_folder)) for metric, tfidf in combinations]\n",
    "    output = [p.get() for p in results]\n",
    "for result in output:\n",
    "    print(result[0], result[1], '\\b:', result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive(f'{qual_eval_folder}/evaluation', 'zip', f'{qual_eval_folder}/source')\n",
    "shutil.rmtree(f'{qual_eval_folder}/source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32135it [00:01, 21678.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 32135 rows.\n"
     ]
    }
   ],
   "source": [
    "shutil.unpack_archive(f'{qual_eval_folder}/evaluation.zip', qual_eval_folder)\n",
    "\n",
    "import glob\n",
    "games = parse_json(\"./data/steam_games.json\")\n",
    "games = games[['id', 'app_name']]\n",
    "mapping = dict(zip(games.id, games.app_name))\n",
    "for f in glob.glob(f'{qual_eval_folder}/*.csv'):\n",
    "    map_id_to_name(mapping, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64dc3e748883430fd73e07c7431dac127012ab88bcfa4187114a89d6e3756f23"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
